{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    @article{ZHENG2023121607,\\n    title = {Interpretable building energy consumption forecasting using spectral clustering algorithm and temporal fusion transformers architecture},\\n    journal = {Applied Energy},\\n    volume = {349},\\n    pages = {121607},\\n    year = {2023},\\n    issn = {0306-2619},\\n    doi = {https://doi.org/10.1016/j.apenergy.2023.121607},\\n    url = {https://www.sciencedirect.com/science/article/pii/S0306261923009716},\\n    author = {Peijun Zheng and Heng Zhou and Jiang Liu and Yosuke Nakanishi},\\n    keywords = {Building energy consumption forecasting, Attention mechanism, Interpretable decomposition method, Interpretable deep learning model},\\n    abstract = {Accurate building energy consumption forecasting is crucial for developing efficient building energy management systems, improving energy efficiency, and local building energy supervision and management. However, short-term building energy consumption forecasting is challenging due to highly non-smooth and volatile trends. In this paper, we present a novel methodology that combines interpretable decomposition methods with an interpretable forecasting model. We first illustrate a daily energy consumption pattern recognition (DECPR) method, which decomposes daily energy consumption patterns into interpretable energy consumption subsequences. To achieve satisfactory forecasting performance, we design the vector representation of each subsequence as a static input to the temporal fusion transformers (TFT) model. This vector representation integrates the DECPR method into the TFT model. The TFT model produces interpretable outputs, such as the attention analysis of different step lengths and the visualization of the importance ranking of exogenous variables, including meteorological data, calendar information, and the vector representation. Empirical studies demonstrate that our proposed DECPR-TFT system outperforms comparable models with a mean absolute percentage error (MAPE) of 6.11%, which is significantly lower than other models. These interpretable outputs provide valuable insights for researchers seeking to develop energy-saving operation strategies in buildings. Overall, our methodology offers a promising solution for short-term building energy consumption forecasting that can contribute to more efficient building energy management and energy-saving operation strategies.}\\n    }\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters ref\n",
    "'''\n",
    "    @article{ZHENG2023121607,\n",
    "    title = {Interpretable building energy consumption forecasting using spectral clustering algorithm and temporal fusion transformers architecture},\n",
    "    journal = {Applied Energy},\n",
    "    volume = {349},\n",
    "    pages = {121607},\n",
    "    year = {2023},\n",
    "    issn = {0306-2619},\n",
    "    doi = {https://doi.org/10.1016/j.apenergy.2023.121607},\n",
    "    url = {https://www.sciencedirect.com/science/article/pii/S0306261923009716},\n",
    "    author = {Peijun Zheng and Heng Zhou and Jiang Liu and Yosuke Nakanishi},\n",
    "    keywords = {Building energy consumption forecasting, Attention mechanism, Interpretable decomposition method, Interpretable deep learning model},\n",
    "    abstract = {Accurate building energy consumption forecasting is crucial for developing efficient building energy management systems, improving energy efficiency, and local building energy supervision and management. However, short-term building energy consumption forecasting is challenging due to highly non-smooth and volatile trends. In this paper, we present a novel methodology that combines interpretable decomposition methods with an interpretable forecasting model. We first illustrate a daily energy consumption pattern recognition (DECPR) method, which decomposes daily energy consumption patterns into interpretable energy consumption subsequences. To achieve satisfactory forecasting performance, we design the vector representation of each subsequence as a static input to the temporal fusion transformers (TFT) model. This vector representation integrates the DECPR method into the TFT model. The TFT model produces interpretable outputs, such as the attention analysis of different step lengths and the visualization of the importance ranking of exogenous variables, including meteorological data, calendar information, and the vector representation. Empirical studies demonstrate that our proposed DECPR-TFT system outperforms comparable models with a mean absolute percentage error (MAPE) of 6.11%, which is significantly lower than other models. These interpretable outputs provide valuable insights for researchers seeking to develop energy-saving operation strategies in buildings. Overall, our methodology offers a promising solution for short-term building energy consumption forecasting that can contribute to more efficient building energy management and energy-saving operation strategies.}\n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import RNNModel\n",
    "from darts.datasets import WeatherDataset\n",
    "from darts.models import LinearRegressionModel\n",
    "import darts.metrics as metrics\n",
    "from darts.datasets import AirPassengersDataset\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.datasets import AirPassengersDataset\n",
    "from darts.models import TCNModel\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "from optuna.terminator import report_cross_validation_scores\n",
    "\n",
    "from darts.models import TFTModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from darts import TimeSeries\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_base():\n",
    "    # set basic settings:\n",
    "    # 1. model identification\n",
    "    # 2. params of model, and whether call optuna\n",
    "    # 3. prediction settings\n",
    "    # 2. saving settings\n",
    "    def __init__(self,id, model_type,\n",
    "                 call_optuna, optuna_settings, optuna_params_dic,\n",
    "                 call_one_trial, one_trial_settings, one_trial_params_dic,\n",
    "                 load_from_trained_model,load_settings,\n",
    "                 load_from_checkpoint,load_checkpoint_settings,\n",
    "                 predict_settings,metric_settings, save_settings):\n",
    "        # for optuna params_dic should be like:\n",
    "        #   dic={\n",
    "        #       'param_key':[tpye, lower_bound, upper_bound, bool_log], #params to search\n",
    "        #       'param_key':[value] #params not to search\n",
    "        #   }\n",
    "        # check if necessary key pairs are passed\n",
    "        \n",
    "        for i in ['folder','save_model','save_prediction','save_metrics']:\n",
    "            assert i in save_settings.keys()\n",
    "            \n",
    "        self.model_type=model_type\n",
    "        self.model=None # tmp model for optuna / model load from file\n",
    "        \n",
    "        self.save_settings=save_settings\n",
    "        self.save_path=os.path.join(save_settings['folder'],id)\n",
    "        self.id=id\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "        \n",
    "        self.call_optuna=call_optuna\n",
    "        if call_optuna==True:\n",
    "            assert optuna_settings!=None\n",
    "            assert optuna_params_dic!=None\n",
    "        self.optuna_params_dic=optuna_params_dic\n",
    "        self.optuna_settings=optuna_settings\n",
    "        self.optuna_model_name=None\n",
    "        \n",
    "        self.call_one_trial=call_one_trial\n",
    "        if call_one_trial==True:\n",
    "            assert one_trial_settings!=None\n",
    "            assert one_trial_params_dic!=None\n",
    "        self.one_trial_params_dic=one_trial_params_dic\n",
    "        self.one_trial_settings=one_trial_settings\n",
    "        self.one_trial_model_name=None\n",
    "        \n",
    "        self.load_from_trained_model=load_from_trained_model\n",
    "        if load_from_trained_model==True:\n",
    "            assert load_settings!=None\n",
    "            self.load_settings=load_settings\n",
    "            self.load_from_model()\n",
    "            \n",
    "        self.load_from_checkpoint=load_from_checkpoint\n",
    "        if load_from_checkpoint==True:\n",
    "            assert load_checkpoint_settings!=None\n",
    "            self.load_checkpoint_settings=load_checkpoint_settings\n",
    "            self.load_from_checkpoints()\n",
    "        \n",
    "        \n",
    "        self.predict_settings=predict_settings\n",
    "        self.metric_settings=metric_settings\n",
    "        \n",
    "\n",
    "        \n",
    "        self.optuna_study=None\n",
    "        self.best_params=None\n",
    "        self.best_model=None\n",
    "        \n",
    "        self.one_trial_model=None # model from run_one_trial\n",
    "        \n",
    "        ...\n",
    "    def load_from_model(self):\n",
    "        self.model=self.model_type.load(**self.load_settings)\n",
    "        ...\n",
    "        \n",
    "    def load_from_checkpoint(self):\n",
    "        self.model=self.model_type.load_from_checkpoint(**self.load_checkpoint_settings)\n",
    "    # run one trial on designated params\n",
    "    def run_one_trial(self):\n",
    "        now=datetime.datetime.now()\n",
    "        self.one_trial_model_name='-'.join([str(now.month),str(now.day),str(now.hour),str(now.minute),'one_trial'])\n",
    "        \n",
    "        self.one_trial_model=self.model_type(work_dir=self.save_path,\n",
    "                                             model_name=self.one_trial_model_name, log_tensorboard=True,\n",
    "                                             save_checkpoints=True,\n",
    "                                             **self.one_trial_params_dic)\n",
    "        #self.one_trial_model, optimizer = amp.initialize(self.one_trial_model, optimizer, opt_level='O1')\n",
    "\n",
    "        self.one_trial_model.fit(**self.one_trial_settings)\n",
    "        \n",
    "    # run hyperparams searching\n",
    "    def run_optuna(self):\n",
    "        p=self.optuna_params_dic\n",
    "        \n",
    "        X_train=self.optuna_settings['X_train']\n",
    "        y_train=self.optuna_settings['y_train']\n",
    "        metric_cv=self.optuna_settings['metric_cv']\n",
    "        n_trials=self.optuna_settings['n_trials']\n",
    "        stop_threshold=self.optuna_settings['stop_threshold']\n",
    "        direction=self.optuna_settings['direction']\n",
    "        \n",
    "        def objective(trial):\n",
    "            params={}\n",
    "            for i in p:\n",
    "                if len(p[i])==1:\n",
    "                    params.update({i:p[i][0]})\n",
    "                elif len(p[i])==4:\n",
    "                    #assert isinstance(p[i][1],p[i][0])\n",
    "                    #assert isinstance(p[i][2],p[i][0])\n",
    "                    if i =='lr':\n",
    "                        params.update({'optimizer_kwargs':\n",
    "                            {i:trial.suggest_float(i,p[i][1],p[i][2],log=p[i][3])}})\n",
    "                    else:\n",
    "                        if p[i][0]==int:\n",
    "                            params.update({i:trial.suggest_int(i,p[i][1],p[i][2],log=p[i][3])})\n",
    "                        elif p[i][0]==float:\n",
    "                            params.update({i:trial.suggest_float(i,p[i][1],p[i][2],log=p[i][3])})\n",
    "                        elif p[i][0]==bool:\n",
    "                            params.update({i:trial.suggest_categorical(i,p[i][1],[p[i][2],p[i][3]])})\n",
    "                        else:\n",
    "                            Warning(\"Invalid param type!\")\n",
    "            model=RNNModel(**params)\n",
    "            model.fit(**self.one_trial_settings)\n",
    "            scores=cross_val_score(model, X_train, y_train,\n",
    "                                   cv=KFold(n_splits=5,shuffle=True),\n",
    "                                   scoring=metric_cv)\n",
    "            report_cross_validation_scores(trial, scores)\n",
    "            \n",
    "            return scores.mean()\n",
    "        \n",
    "        def callback(study, trial):\n",
    "            for ii, t in enumerate(study.trials):\n",
    "                if t.value >= stop_threshold:\n",
    "                    study.stop()\n",
    "                    \n",
    "        study = optuna.create_study(direction=direction)\n",
    "        \n",
    "        study.optimize(objective, n_trials=n_trials, gc_after_trial=True,\n",
    "                   callbacks=[callback])\n",
    "    \n",
    "        print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "        print('Best trial:')\n",
    "        trial = study.best_trial\n",
    "\n",
    "        print('  Value: {}'.format(trial.value))\n",
    "        print('  Params: ')\n",
    "\n",
    "        for key, value in trial.params.items():\n",
    "            print('    {}: {}'.format(key, value))\n",
    "            \n",
    "        self.optuna_study=study\n",
    "        return study\n",
    "    \n",
    "    def refit_best_trial(self):\n",
    "        assert self.optuna_study!=None\n",
    "        best_trail=self.optuna_study.best_trial\n",
    "        best_params=best_trail.params\n",
    "        #best_params['tree_method']='gpu_hist'\n",
    "        self.best_params=best_params\n",
    "        model=self.model_type(**self.best_params)\n",
    "        model.fit(self.optuna_setting['X_train'],self.optuna_setting['y_train'])\n",
    "        self.best_model=model\n",
    "        return model\n",
    "    \n",
    "    def save_one_trial_model(self):\n",
    "        assert self.one_trial_model !=None\n",
    "        model_path=os.path.join(self.save_path,self.one_trial_model_name,'trained_model')\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "        model_name=self.one_trial_model_name\n",
    "        model_name=os.path.join(model_path,model_name+'.pt')\n",
    "        self.one_trial_model.save(model_name)\n",
    "        \n",
    "    def predict_on_one_trial_model(self):\n",
    "        self.prediction=self.one_trial_model.predict(**self.predict_settings)\n",
    "        self.prediction.to_csv(os.path.join(self.save_path,self.one_trial_model_name+'prediction.csv'))\n",
    "        \n",
    "    def predict_on_best_model(self):\n",
    "        self.prediction=self.best_model.predict(**self.predict_settings)\n",
    "        self.prediction.to_csv(os.path.join(self.save_path,self.optuna_model_name+'prediction.csv'))\n",
    "        \n",
    "    def predict_on_loaded_model(self):\n",
    "        self.prediction=self.model.predict(**self.predict_settings)\n",
    "        self.prediction.to_csv(os.path.join(self.save_path,'loaded_model_prediction.csv'))\n",
    "\n",
    "    def cal_metrics(self):\n",
    "        assert self.prediction!=None\n",
    "        metrics_method_dic={\n",
    "            'CV':metrics.coefficient_of_variation,\n",
    "            'MAE':metrics.mae,\n",
    "            'MAPE':metrics.mape,\n",
    "            'OPE':metrics.ope,\n",
    "            'RMSE':metrics.rmse,\n",
    "            'MSE':metrics.mse,\n",
    "            'MARRE':metrics.marre,\n",
    "            'MASE':metrics.mase,\n",
    "            'R2':metrics.r2_score,\n",
    "            'SMAPE':metrics.smape,\n",
    "        }\n",
    "        metrics_dic={\n",
    "            'start_time':self.prediction.time_index[0],\n",
    "            'end_time':self.prediction.time_index[-1],\n",
    "            'n':len(self.prediction.time_index),\n",
    "        }\n",
    "        \n",
    "        for metric in metrics_method_dic.keys():\n",
    "            try:\n",
    "                if metric=='MASE':\n",
    "                    value=metrics_method_dic[metric](self.metric_settings['series_pred_gt'],self.prediction,intersect=True,\n",
    "                                                              insample=self.metric_settings['series_train'], m=96*7)\n",
    "                    print({metric: value})\n",
    "                    metrics_dic.update({metric: value})\n",
    "                else:\n",
    "                    value=metrics_method_dic[metric](self.metric_settings['series_pred_gt'],self.prediction,intersect=True)\n",
    "                    print({metric: value})\n",
    "                    metrics_dic.update({metric: value})\n",
    "            except:\n",
    "                print(\"Fail to calculate metric: {} of model {}\".format(metric,self.id))\n",
    "                \n",
    "        metrics_df=pd.DataFrame([metrics_dic]).T\n",
    "        metrics_df.to_csv(os.path.join(self.save_path,self.id+'_metrics.csv'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probolistic RNN resembles DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\n",
    "from darts.metrics import mape\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "import darts.utils.timeseries_generation as tg\n",
    "from darts.datasets import AirPassengersDataset, EnergyDataset\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.utils.missing_values import fill_missing_values\n",
    "from darts.utils.likelihood_models import GaussianLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preperation\n",
    "bld_pd=pd.read_csv(r'/root/autodl-tmp/data/load_prediction_base/BLD_Sum.csv')\n",
    "bld_pd.sort_values(by='DateTime')\n",
    "bld_pd=bld_pd.drop(columns=['RealPower_before_scaling'])\n",
    "bld=TimeSeries.from_dataframe(bld_pd,time_col=\"DateTime\",freq=\"15min\",fill_missing_dates=True)\n",
    "\n",
    "bld=bld.drop_columns(['wind_speed', 'wind_deg', 'rain_1h',\n",
    "       'rain_3h', 'snow_1h', 'snow_3h', 'clouds_all', 'weather_main',\n",
    "       'RealPower_-0d_0h'])\n",
    "\n",
    "transformer = Scaler()\n",
    "\n",
    "# data split\n",
    "train_start=pd.Timestamp(2017,1,1,0,0)\n",
    "train_end=pd.Timestamp(2018,12,31,23,45)\n",
    "\n",
    "val_start=pd.Timestamp(2018,1,1,0,0)\n",
    "val_end=pd.Timestamp(2018,12,31,23,45)\n",
    "\n",
    "pred_start=pd.Timestamp(2019,1,1,0,0)\n",
    "pred_end=pd.Timestamp(2019,12,31,23,45)\n",
    "\n",
    "bld_train=bld[train_start:train_end]\n",
    "bld_val=bld[val_start:val_end]\n",
    "bld_pred=bld[pred_start:pred_end]\n",
    "\n",
    "bld_trian=transformer.fit_transform(bld_train)\n",
    "bld_val=transformer.fit_transform(bld_val)\n",
    "#bld_trian=transformer.fit_transform(bld_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-11 02:34:43,859] A new study created in memory with name: no-name-7374ebe4-3101-42a6-84af-45a75117cc48\n",
      "ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rnn           | LSTM             | 2.3 M \n",
      "4 | V             | Linear           | 229   \n",
      "---------------------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.260     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8cf1d0336d49c18eb0de0989af3ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[W 2023-10-11 02:39:16,484] Trial 0 failed with parameters: {'lr': 0.05464417165024453, 'hidden_dim': 228, 'n_rnn_layers': 6, 'batch_size': 20, 'dropout': 0.413666970231875, 'n_epochs': 2} because of the following error: TypeError(\"Cannot clone object 'RNNModel(model=LSTM, hidden_dim=228, n_rnn_layers=6, dropout=0.413666970231875, training_length=24, optimizer_kwargs={'lr': 0.05464417165024453}, batch_size=20, input_chunk_length=672, output_chunk_length=96, n_epochs=2, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': [0]}, random_state=42)' (type <class 'darts.models.forecasting.rnn_model.RNNModel'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1259/538616787.py\", line 125, in objective\n",
      "    scores=cross_val_score(model, X_train, y_train,\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 562, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 309, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1789, in _get_sequential_output\n",
      "    for func, args, kwargs in iterable:\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 61, in <genexpr>\n",
      "    iterable_with_config = (\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 311, in <genexpr>\n",
      "    clone(estimator),\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/sklearn/base.py\", line 76, in clone\n",
      "    return _clone_parametrized(estimator, safe=safe)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/sklearn/base.py\", line 98, in _clone_parametrized\n",
      "    raise TypeError(\n",
      "TypeError: Cannot clone object 'RNNModel(model=LSTM, hidden_dim=228, n_rnn_layers=6, dropout=0.413666970231875, training_length=24, optimizer_kwargs={'lr': 0.05464417165024453}, batch_size=20, input_chunk_length=672, output_chunk_length=96, n_epochs=2, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': [0]}, random_state=42)' (type <class 'darts.models.forecasting.rnn_model.RNNModel'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
      "[W 2023-10-11 02:39:16,485] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object 'RNNModel(model=LSTM, hidden_dim=228, n_rnn_layers=6, dropout=0.413666970231875, training_length=24, optimizer_kwargs={'lr': 0.05464417165024453}, batch_size=20, input_chunk_length=672, output_chunk_length=96, n_epochs=2, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': [0]}, random_state=42)' (type <class 'darts.models.forecasting.rnn_model.RNNModel'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/autodl-tmp/load_forecast/DeepAR(Prob_RNN).ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 109>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m save_settings\u001b[39m=\u001b[39m{\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfolder\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/root/autodl-tmp/load_forecast/DeepAR(Prob_RNN)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msave_model\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mTrue\u001b[39;00m,\u001b[39m'\u001b[39m\u001b[39msave_prediction\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mTrue\u001b[39;00m,\u001b[39m'\u001b[39m\u001b[39msave_metrics\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m test\u001b[39m=\u001b[39mModel_base(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m     \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtry_optuna\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m     model_type\u001b[39m=\u001b[39mRNNModel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m     save_settings\u001b[39m=\u001b[39msave_settings\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=108'>109</a>\u001b[0m test\u001b[39m.\u001b[39;49mrun_optuna()\n",
      "\u001b[1;32m/root/autodl-tmp/load_forecast/DeepAR(Prob_RNN).ipynb Cell 7\u001b[0m line \u001b[0;36mModel_base.run_optuna\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m             study\u001b[39m.\u001b[39mstop()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39mdirection)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49mn_trials, gc_after_trial\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=139'>140</a>\u001b[0m            callbacks\u001b[39m=\u001b[39;49m[callback])\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=141'>142</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of finished trials: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials)))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=142'>143</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     _optimize(\n\u001b[1;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    452\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/root/autodl-tmp/load_forecast/DeepAR(Prob_RNN).ipynb Cell 7\u001b[0m line \u001b[0;36mModel_base.run_optuna.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=122'>123</a>\u001b[0m model\u001b[39m=\u001b[39mRNNModel(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=123'>124</a>\u001b[0m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone_trial_settings)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=124'>125</a>\u001b[0m scores\u001b[39m=\u001b[39mcross_val_score(model, X_train, y_train,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m                        cv\u001b[39m=\u001b[39;49mKFold(n_splits\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=126'>127</a>\u001b[0m                        scoring\u001b[39m=\u001b[39;49mmetric_cv)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=127'>128</a>\u001b[0m report_cross_validation_scores(trial, scores)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B3090-3/root/autodl-tmp/load_forecast/DeepAR%28Prob_RNN%29.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1786\u001b[0m \u001b[39myield\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[39m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[0;32m-> 1789\u001b[0m \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1790\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py:61\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m---> 61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:311\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m    309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m--> 311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39m__sklearn_clone__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(estimator):\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[39m=\u001b[39;49msafe)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/base.py:98\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[1;32m    103\u001b[0m             )\n\u001b[1;32m    105\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[1;32m    106\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object 'RNNModel(model=LSTM, hidden_dim=228, n_rnn_layers=6, dropout=0.413666970231875, training_length=24, optimizer_kwargs={'lr': 0.05464417165024453}, batch_size=20, input_chunk_length=672, output_chunk_length=96, n_epochs=2, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': [0]}, random_state=42)' (type <class 'darts.models.forecasting.rnn_model.RNNModel'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "model_type=RNNModel\n",
    "call_optuna=True\n",
    "optuna_settings={\n",
    "    'X_train':bld_train.drop_columns(['RealPower']),\n",
    "    'y_train':bld_train['RealPower'],\n",
    "    'metric_cv':'neg_mean_absolute_error',\n",
    "    'n_trials':1,\n",
    "    'stop_threshold':0.1,\n",
    "    'direction':'maximize',\n",
    "    \n",
    "}\n",
    "optuna_params_dic={\n",
    "    'lr':[float, 1e-5, 1e-1, False],\n",
    "    'model':['LSTM'],\n",
    "    'hidden_dim':[int, 8, 256, False],\n",
    "    'n_rnn_layers':[int,1,8,False],\n",
    "    'batch_size':[int,8,96*2,False],\n",
    "    'dropout':[float,0.01,0.5,False],\n",
    "    'input_chunk_length':[96*7],\n",
    "    'output_chunk_length':[96],\n",
    "    'n_epochs':[int,1,2,False],\n",
    "    'pl_trainer_kwargs':[{\n",
    "      \"accelerator\": \"gpu\",\n",
    "      \"devices\": [0]\n",
    "    }],\n",
    "    'random_state':[42],\n",
    "}\n",
    "call_one_trial=False\n",
    "quantiles = [\n",
    "    0.01,0.05,0.1,0.15,0.2,0.25,0.3,0.4,0.5,\n",
    "    0.6,0.7,0.75,0.8,0.85,0.9,0.95,0.99,\n",
    "]\n",
    "\n",
    "one_trial_settings={\n",
    "    'series':bld_train['RealPower'],\n",
    "    'future_covariates':bld_train.drop_columns(['RealPower']),\n",
    "    #'val_series':bld_val['RealPower'],\n",
    "    #'val_future_covariates':bld_val.drop_columns(['RealPower'])\n",
    "}\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    min_delta=1e-5,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "one_trial_params_dic={\n",
    "    'optimizer_kwargs':{\n",
    "        'lr':1e-4,\n",
    "    },\n",
    "    'pl_trainer_kwargs':{\n",
    "        \"callbacks\": [my_stopper],\n",
    "        \"gradient_clip_val\":0.1},\n",
    "    'model':'LSTM',\n",
    "    'hidden_dim':128,\n",
    "    'n_rnn_layers':4,\n",
    "    'batch_size':64,\n",
    "    'dropout':0.2,\n",
    "    'input_chunk_length':96*7,\n",
    "    'output_chunk_length':96,\n",
    "    #'loss_fn':torch.nn.GaussianNLLLoss(reduction='mean'),\n",
    "    #'likelihood':GaussianLikelihood(),\n",
    "    # QuantileRegression(\n",
    "    #    quantiles=quantiles\n",
    "    #),\n",
    "    'n_epochs':10,\n",
    "    'pl_trainer_kwargs':{\n",
    "      \"accelerator\": \"gpu\",\n",
    "      \"devices\": [0]\n",
    "    },\n",
    "    'random_state':42,\n",
    "}\n",
    "'''    \n",
    "'likelihood':QuantileRegression(\n",
    "        quantiles=quantiles\n",
    "    ),'''\n",
    "predict_settings={\n",
    "    'n':96*365,\n",
    "    'series':bld_train['RealPower'],\n",
    "    'future_covariates':bld.drop_columns(['RealPower']),\n",
    "    'n_jobs':-1,\n",
    "    'num_samples':1\n",
    "}\n",
    "metric_settings={\n",
    "    'series_pred_gt':bld_pred['RealPower'],\n",
    "    'series_train':bld_train['RealPower'],\n",
    "}\n",
    "save_settings={\n",
    "    'folder':r'/root/autodl-tmp/load_forecast/DeepAR(Prob_RNN)',\n",
    "    'save_model':True,'save_prediction':True,'save_metrics':True\n",
    "}\n",
    "test=Model_base(\n",
    "    id='try_optuna',\n",
    "    model_type=RNNModel,\n",
    "    call_optuna=True,\n",
    "    optuna_settings=optuna_settings,\n",
    "    optuna_params_dic=optuna_params_dic,\n",
    "    call_one_trial=True,\n",
    "    one_trial_settings=one_trial_settings,\n",
    "    one_trial_params_dic=one_trial_params_dic,\n",
    "    load_from_trained_model=False,\n",
    "    load_settings=None,\n",
    "    load_from_checkpoint=False,\n",
    "    load_checkpoint_settings=None,\n",
    "    predict_settings=predict_settings,\n",
    "    metric_settings=metric_settings,\n",
    "    save_settings=save_settings\n",
    ")\n",
    "test.run_optuna()\n",
    "#test.save_one_trial_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60713cd9dff14ca2a9b3b29d9c63ffc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.refit_best_trial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CV': 22.176691856419975}\n",
      "{'MAE': 13.980581074241446}\n",
      "{'MAPE': 20.528752670935834}\n",
      "{'OPE': 2.595183476391746}\n",
      "{'RMSE': 16.127937103539352}\n",
      "{'MSE': 260.11035521572137}\n",
      "{'MARRE': 19.473432787052577}\n",
      "{'MASE': 3.002026990660021}\n",
      "{'R2': -0.013884527538935876}\n",
      "{'SMAPE': 19.249988436986946}\n"
     ]
    }
   ],
   "source": [
    "test.cal_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
